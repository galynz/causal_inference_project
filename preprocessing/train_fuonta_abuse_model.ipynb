{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Model",
      "provenance": [],
      "collapsed_sections": [
        "8uWdvquZKUe2"
      ],
      "authorship_tag": "ABX9TyP5cjo30k9aFfIlwYI7tiMG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galynz/causal_inference_project/blob/master/preprocessing/train_fuonta_abuse_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XA9IOw_Qy8q",
        "colab_type": "text"
      },
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMrV8lCLQ5Mi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Add custom metrics to the model building\n",
        "*   Change the preprocess to be more accurate (or check that Tokenizer works as intended)\n",
        "*   Preprocess Metadata\n",
        "*   Add second head for metadata classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLtsVhl4nuHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uWdvquZKUe2",
        "colab_type": "text"
      },
      "source": [
        "# Mounting Drive For Data\n",
        "\n",
        "(not relevant for now. Please upload data manually)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4fvHiccDCXN",
        "colab_type": "code",
        "outputId": "de615cc8-3db6-4776-ff8e-98f729c24731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhNbmDI6Dp9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls /content/drive/My\\ Drive/Research"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lIV-hrOxbfQ",
        "colab_type": "text"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0YoseWGxaUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy4g9vfOxfTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_df = pd.read_csv(\"./hatespeech_features.csv\", lineterminator='\\n', index_col=0)\n",
        "labels_df = pd.read_csv(\"./hatespeech_labels.csv\", index_col=0, dtype={\"label\": \"category\"})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9ZGlNBOL2ht",
        "colab_type": "text"
      },
      "source": [
        "# Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7s-f9l_EgwY",
        "colab_type": "code",
        "outputId": "9f3b8faa-3591-4d86-82ec-116768361d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, GlobalMaxPooling1D, GRU\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.initializers import Constant\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2PqJ8hXAmNW",
        "colab_type": "text"
      },
      "source": [
        "Preparing the data:\n",
        "\n",
        "(todo: change the Tokenizer to sklearn and the required tokenizing for tweeter. In other words: more preprocess.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtfpSd17xQdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_NUM_WORDS = 20000\n",
        "MAX_SEQUENCE_LENGTH = 30\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(features_df[\"text\"])\n",
        "sequences = tokenizer.texts_to_sequences(features_df[\"text\"])\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "labels = to_categorical(np.asarray(labels_df.loc[features_df.index, \"label\"].cat.codes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-II2SAiBBqB",
        "colab_type": "text"
      },
      "source": [
        "Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY7bEhj8BBN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain, Xtest, ytrain, ytest = train_test_split(data, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gefJ0EgAqg-",
        "colab_type": "text"
      },
      "source": [
        "Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJpYXpyxA2ZP",
        "colab_type": "code",
        "outputId": "aad86257-5943-4d3b-cb54-90c97df73f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "source": [
        "# Getting the GloVE embedding layer\n",
        "import gensim.downloader as api\n",
        "glove = api.load(\"glove-twitter-200\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 758.5/758.5MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SQTFh_uL98K",
        "colab_type": "code",
        "outputId": "7003cd22-fe52-4022-e37d-071f6277988e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        }
      },
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = glove.get_keras_embedding()(sequence_input)\n",
        "x = GRU(128, recurrent_dropout=0.5)(embedded_sequences)\n",
        "# x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
        "# x = MaxPooling1D(5)(x)\n",
        "# x = Conv1D(128, 5, activation='relu')(x)\n",
        "# x = GlobalMaxPooling1D()(x)\n",
        "#x = Dense(128, activation='relu')(x)\n",
        "preds = Dense(len(labels_df.loc[features_df.index, \"label\"].cat.categories), activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edqIdJbAoIiB",
        "colab_type": "code",
        "outputId": "6c1c8a43-436c-4089-d5a4-050f20d228b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVE6lDJ7ALJK",
        "colab_type": "code",
        "outputId": "abec8e91-2be0-463c-c123-3d299c4effd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "K.get_session().run(tf.local_variables_initializer())\n",
        "model.fit(\n",
        "    Xtrain, ytrain, batch_size=512, epochs=1000,\n",
        "    validation_data=(Xtest, ytest)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 74849 samples, validate on 24950 samples\n",
            "Epoch 1/1000\n",
            "74849/74849 [==============================] - 53s 708us/step - loss: 0.8576 - acc: 0.6634 - val_loss: 0.6913 - val_acc: 0.7445\n",
            "Epoch 2/1000\n",
            "74849/74849 [==============================] - 53s 703us/step - loss: 0.6630 - acc: 0.7543 - val_loss: 0.6259 - val_acc: 0.7660\n",
            "Epoch 3/1000\n",
            "74849/74849 [==============================] - 53s 708us/step - loss: 0.6056 - acc: 0.7748 - val_loss: 0.5867 - val_acc: 0.7807\n",
            "Epoch 4/1000\n",
            "74849/74849 [==============================] - 52s 699us/step - loss: 0.5721 - acc: 0.7880 - val_loss: 0.5665 - val_acc: 0.7890\n",
            "Epoch 5/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.5517 - acc: 0.7954 - val_loss: 0.5561 - val_acc: 0.7937\n",
            "Epoch 6/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.5359 - acc: 0.8017 - val_loss: 0.5511 - val_acc: 0.7956\n",
            "Epoch 7/1000\n",
            "74849/74849 [==============================] - 52s 696us/step - loss: 0.5225 - acc: 0.8075 - val_loss: 0.5522 - val_acc: 0.7935\n",
            "Epoch 8/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.5109 - acc: 0.8111 - val_loss: 0.5401 - val_acc: 0.7997\n",
            "Epoch 9/1000\n",
            "74849/74849 [==============================] - 52s 700us/step - loss: 0.4993 - acc: 0.8157 - val_loss: 0.5392 - val_acc: 0.8014\n",
            "Epoch 10/1000\n",
            "74849/74849 [==============================] - 52s 693us/step - loss: 0.4906 - acc: 0.8178 - val_loss: 0.5365 - val_acc: 0.8022\n",
            "Epoch 11/1000\n",
            "74849/74849 [==============================] - 52s 694us/step - loss: 0.4821 - acc: 0.8207 - val_loss: 0.5350 - val_acc: 0.8032\n",
            "Epoch 12/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.4714 - acc: 0.8237 - val_loss: 0.5373 - val_acc: 0.8033\n",
            "Epoch 13/1000\n",
            "74849/74849 [==============================] - 52s 693us/step - loss: 0.4661 - acc: 0.8262 - val_loss: 0.5350 - val_acc: 0.8028\n",
            "Epoch 14/1000\n",
            "74849/74849 [==============================] - 52s 694us/step - loss: 0.4572 - acc: 0.8298 - val_loss: 0.5377 - val_acc: 0.8024\n",
            "Epoch 15/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.4488 - acc: 0.8316 - val_loss: 0.5461 - val_acc: 0.7949\n",
            "Epoch 16/1000\n",
            "74849/74849 [==============================] - 52s 694us/step - loss: 0.4396 - acc: 0.8360 - val_loss: 0.5438 - val_acc: 0.8022\n",
            "Epoch 17/1000\n",
            "74849/74849 [==============================] - 52s 693us/step - loss: 0.4333 - acc: 0.8371 - val_loss: 0.5460 - val_acc: 0.7958\n",
            "Epoch 18/1000\n",
            "74849/74849 [==============================] - 52s 691us/step - loss: 0.4254 - acc: 0.8402 - val_loss: 0.5467 - val_acc: 0.8012\n",
            "Epoch 19/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.4179 - acc: 0.8431 - val_loss: 0.5461 - val_acc: 0.7999\n",
            "Epoch 20/1000\n",
            "74849/74849 [==============================] - 52s 693us/step - loss: 0.4108 - acc: 0.8455 - val_loss: 0.5513 - val_acc: 0.7999\n",
            "Epoch 21/1000\n",
            "74849/74849 [==============================] - 53s 705us/step - loss: 0.4036 - acc: 0.8476 - val_loss: 0.5537 - val_acc: 0.8001\n",
            "Epoch 22/1000\n",
            "74849/74849 [==============================] - 52s 690us/step - loss: 0.3976 - acc: 0.8504 - val_loss: 0.5590 - val_acc: 0.8004\n",
            "Epoch 23/1000\n",
            "74849/74849 [==============================] - 52s 694us/step - loss: 0.3902 - acc: 0.8534 - val_loss: 0.5613 - val_acc: 0.7978\n",
            "Epoch 24/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.3841 - acc: 0.8563 - val_loss: 0.5675 - val_acc: 0.7978\n",
            "Epoch 25/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.3780 - acc: 0.8580 - val_loss: 0.5717 - val_acc: 0.7985\n",
            "Epoch 26/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.3707 - acc: 0.8601 - val_loss: 0.5820 - val_acc: 0.7985\n",
            "Epoch 27/1000\n",
            "74849/74849 [==============================] - 52s 700us/step - loss: 0.3651 - acc: 0.8619 - val_loss: 0.5893 - val_acc: 0.7930\n",
            "Epoch 28/1000\n",
            "74849/74849 [==============================] - 52s 690us/step - loss: 0.3594 - acc: 0.8640 - val_loss: 0.5859 - val_acc: 0.7954\n",
            "Epoch 29/1000\n",
            "74849/74849 [==============================] - 52s 691us/step - loss: 0.3543 - acc: 0.8659 - val_loss: 0.5921 - val_acc: 0.7947\n",
            "Epoch 30/1000\n",
            "74849/74849 [==============================] - 52s 693us/step - loss: 0.3481 - acc: 0.8689 - val_loss: 0.5998 - val_acc: 0.7934\n",
            "Epoch 31/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.3429 - acc: 0.8703 - val_loss: 0.6054 - val_acc: 0.7950\n",
            "Epoch 32/1000\n",
            "74849/74849 [==============================] - 52s 699us/step - loss: 0.3378 - acc: 0.8723 - val_loss: 0.6014 - val_acc: 0.7930\n",
            "Epoch 33/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.3320 - acc: 0.8746 - val_loss: 0.6143 - val_acc: 0.7893\n",
            "Epoch 34/1000\n",
            "74849/74849 [==============================] - 52s 696us/step - loss: 0.3266 - acc: 0.8775 - val_loss: 0.6212 - val_acc: 0.7927\n",
            "Epoch 35/1000\n",
            "74849/74849 [==============================] - 52s 696us/step - loss: 0.3216 - acc: 0.8796 - val_loss: 0.6282 - val_acc: 0.7876\n",
            "Epoch 36/1000\n",
            "74849/74849 [==============================] - 52s 695us/step - loss: 0.3193 - acc: 0.8798 - val_loss: 0.6363 - val_acc: 0.7925\n",
            "Epoch 37/1000\n",
            "74849/74849 [==============================] - 54s 717us/step - loss: 0.3116 - acc: 0.8825 - val_loss: 0.6333 - val_acc: 0.7906\n",
            "Epoch 38/1000\n",
            "74849/74849 [==============================] - 54s 724us/step - loss: 0.3057 - acc: 0.8854 - val_loss: 0.6390 - val_acc: 0.7883\n",
            "Epoch 39/1000\n",
            "74849/74849 [==============================] - 53s 703us/step - loss: 0.3048 - acc: 0.8865 - val_loss: 0.6421 - val_acc: 0.7884\n",
            "Epoch 40/1000\n",
            "74849/74849 [==============================] - 54s 726us/step - loss: 0.3013 - acc: 0.8872 - val_loss: 0.6561 - val_acc: 0.7908\n",
            "Epoch 41/1000\n",
            "74849/74849 [==============================] - 52s 698us/step - loss: 0.2948 - acc: 0.8888 - val_loss: 0.6646 - val_acc: 0.7822\n",
            "Epoch 42/1000\n",
            "74849/74849 [==============================] - 52s 701us/step - loss: 0.2899 - acc: 0.8910 - val_loss: 0.6599 - val_acc: 0.7877\n",
            "Epoch 43/1000\n",
            "74849/74849 [==============================] - 52s 701us/step - loss: 0.2884 - acc: 0.8912 - val_loss: 0.6650 - val_acc: 0.7877\n",
            "Epoch 44/1000\n",
            "74849/74849 [==============================] - 53s 706us/step - loss: 0.2835 - acc: 0.8939 - val_loss: 0.6751 - val_acc: 0.7850\n",
            "Epoch 45/1000\n",
            "74849/74849 [==============================] - 52s 701us/step - loss: 0.2800 - acc: 0.8949 - val_loss: 0.6771 - val_acc: 0.7847\n",
            "Epoch 46/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.2766 - acc: 0.8956 - val_loss: 0.6852 - val_acc: 0.7822\n",
            "Epoch 47/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.2728 - acc: 0.8974 - val_loss: 0.6921 - val_acc: 0.7836\n",
            "Epoch 48/1000\n",
            "74849/74849 [==============================] - 52s 700us/step - loss: 0.2690 - acc: 0.8993 - val_loss: 0.6913 - val_acc: 0.7837\n",
            "Epoch 49/1000\n",
            "74849/74849 [==============================] - 52s 700us/step - loss: 0.2667 - acc: 0.9017 - val_loss: 0.7011 - val_acc: 0.7861\n",
            "Epoch 50/1000\n",
            "74849/74849 [==============================] - 53s 709us/step - loss: 0.2617 - acc: 0.9027 - val_loss: 0.7033 - val_acc: 0.7780\n",
            "Epoch 51/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.2601 - acc: 0.9022 - val_loss: 0.7171 - val_acc: 0.7851\n",
            "Epoch 52/1000\n",
            "74849/74849 [==============================] - 52s 700us/step - loss: 0.2578 - acc: 0.9030 - val_loss: 0.7185 - val_acc: 0.7824\n",
            "Epoch 53/1000\n",
            "74849/74849 [==============================] - 54s 725us/step - loss: 0.2551 - acc: 0.9036 - val_loss: 0.7236 - val_acc: 0.7823\n",
            "Epoch 54/1000\n",
            "74849/74849 [==============================] - 52s 701us/step - loss: 0.2510 - acc: 0.9062 - val_loss: 0.7273 - val_acc: 0.7796\n",
            "Epoch 55/1000\n",
            "74849/74849 [==============================] - 54s 726us/step - loss: 0.2487 - acc: 0.9061 - val_loss: 0.7359 - val_acc: 0.7844\n",
            "Epoch 56/1000\n",
            "74849/74849 [==============================] - 53s 710us/step - loss: 0.2458 - acc: 0.9080 - val_loss: 0.7381 - val_acc: 0.7822\n",
            "Epoch 57/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.2440 - acc: 0.9084 - val_loss: 0.7394 - val_acc: 0.7778\n",
            "Epoch 58/1000\n",
            "74849/74849 [==============================] - 54s 719us/step - loss: 0.2400 - acc: 0.9104 - val_loss: 0.7484 - val_acc: 0.7760\n",
            "Epoch 59/1000\n",
            "74849/74849 [==============================] - 52s 696us/step - loss: 0.2386 - acc: 0.9110 - val_loss: 0.7576 - val_acc: 0.7794\n",
            "Epoch 60/1000\n",
            "74849/74849 [==============================] - 53s 703us/step - loss: 0.2350 - acc: 0.9115 - val_loss: 0.7628 - val_acc: 0.7800\n",
            "Epoch 61/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.2337 - acc: 0.9128 - val_loss: 0.7658 - val_acc: 0.7745\n",
            "Epoch 62/1000\n",
            "74849/74849 [==============================] - 53s 709us/step - loss: 0.2324 - acc: 0.9138 - val_loss: 0.7670 - val_acc: 0.7733\n",
            "Epoch 63/1000\n",
            "74849/74849 [==============================] - 52s 700us/step - loss: 0.2285 - acc: 0.9144 - val_loss: 0.7755 - val_acc: 0.7788\n",
            "Epoch 64/1000\n",
            "74849/74849 [==============================] - 52s 701us/step - loss: 0.2263 - acc: 0.9162 - val_loss: 0.7913 - val_acc: 0.7810\n",
            "Epoch 65/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.2230 - acc: 0.9164 - val_loss: 0.7876 - val_acc: 0.7794\n",
            "Epoch 66/1000\n",
            "74849/74849 [==============================] - 52s 700us/step - loss: 0.2232 - acc: 0.9173 - val_loss: 0.7906 - val_acc: 0.7799\n",
            "Epoch 67/1000\n",
            "74849/74849 [==============================] - 53s 705us/step - loss: 0.2198 - acc: 0.9178 - val_loss: 0.8014 - val_acc: 0.7824\n",
            "Epoch 68/1000\n",
            "74849/74849 [==============================] - 53s 705us/step - loss: 0.2158 - acc: 0.9194 - val_loss: 0.7994 - val_acc: 0.7773\n",
            "Epoch 69/1000\n",
            "74849/74849 [==============================] - 53s 702us/step - loss: 0.2156 - acc: 0.9203 - val_loss: 0.8044 - val_acc: 0.7749\n",
            "Epoch 70/1000\n",
            "74849/74849 [==============================] - 53s 706us/step - loss: 0.2127 - acc: 0.9219 - val_loss: 0.8070 - val_acc: 0.7758\n",
            "Epoch 71/1000\n",
            "74849/74849 [==============================] - 53s 704us/step - loss: 0.2105 - acc: 0.9212 - val_loss: 0.8199 - val_acc: 0.7799\n",
            "Epoch 72/1000\n",
            "74849/74849 [==============================] - 53s 705us/step - loss: 0.2111 - acc: 0.9221 - val_loss: 0.8357 - val_acc: 0.7810\n",
            "Epoch 73/1000\n",
            "74849/74849 [==============================] - 53s 706us/step - loss: 0.2083 - acc: 0.9223 - val_loss: 0.8239 - val_acc: 0.7727\n",
            "Epoch 74/1000\n",
            "74849/74849 [==============================] - 53s 708us/step - loss: 0.2073 - acc: 0.9229 - val_loss: 0.8278 - val_acc: 0.7715\n",
            "Epoch 75/1000\n",
            "35840/74849 [=============>................] - ETA: 24s - loss: 0.1982 - acc: 0.9278"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcLpWRzaAWxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}