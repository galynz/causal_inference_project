{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import ndjson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import gensim\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\nmd\n"
    }
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"..\\\\found_tweets.txt\", \"r\") as fobj:\n",
    "    df = pd.DataFrame(ndjson.load(fobj))\n",
    "labels = pd.read_csv(\"../data/hatespeech_labels.csv\").set_index(\"tweet_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"full_text\"].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\nmd\n"
    }
   },
   "source": [
    "## Detour - TextBlob sentiment\n",
    "\n",
    "It seems that textblob came already with a pretrained sentiment analysis.\n",
    "This might be useful, an we might want to retain on it. However, it seems\n",
    "that the values are not very useful for our usecase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentiments = df.set_index(\"id\")[\"full_text\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "pd.concat([sentiments, labels], axis=1).set_index(\"label\", append=True)[\"full_text\"].unstack().hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>label</th>\n",
       "      <th>abusive</th>\n",
       "      <th>hateful</th>\n",
       "      <th>normal</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11810.000000</td>\n",
       "      <td>2469.000000</td>\n",
       "      <td>38476.000000</td>\n",
       "      <td>8567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.572286</td>\n",
       "      <td>-0.358625</td>\n",
       "      <td>0.117893</td>\n",
       "      <td>0.159780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.283211</td>\n",
       "      <td>0.439207</td>\n",
       "      <td>0.323918</td>\n",
       "      <td>0.319509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.700000</td>\n",
       "      <td>-0.741667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.600000</td>\n",
       "      <td>-0.556250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.366970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "label       abusive      hateful        normal         spam\n",
       "count  11810.000000  2469.000000  38476.000000  8567.000000\n",
       "mean      -0.572286    -0.358625      0.117893     0.159780\n",
       "std        0.283211     0.439207      0.323918     0.319509\n",
       "min       -1.000000    -1.000000     -1.000000    -1.000000\n",
       "25%       -0.700000    -0.741667      0.000000     0.000000\n",
       "50%       -0.600000    -0.556250      0.000000     0.033333\n",
       "75%       -0.600000     0.000000      0.312500     0.366970\n",
       "max        1.000000     1.000000      1.000000     1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([sentiments, labels], axis=1).set_index(\"label\", append=True)[\"full_text\"].unstack().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training A Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.url_re = re.compile(\"^\\w+://\")\n",
    "        self.stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        self.tokenizer = TweetTokenizer(strip_handles=True)\n",
    "        \n",
    "    def __call__(self, doc):\n",
    "        return [\n",
    "            self.stemmer.stem(token) \n",
    "            for token in self.tokenizer.tokenize(doc)\n",
    "            if not self.url_re.match(token)\n",
    "        ]\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"preprocess_text\", ColumnTransformer([\n",
    "        (\"encode_text\", CountVectorizer(\n",
    "                tokenizer=Tokenizer(),\n",
    "                stop_words=stopwords.words(\"english\")\n",
    "        ), \"full_text\")\n",
    "    ])),\n",
    "    (\"classify\", MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.set_index(\"id\")\n",
    "y = labels.loc[X.index, 'label'].replace({\"hateful\": \"abusive\"})\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 26.9min\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed: 30.8min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed: 35.5min\n",
      "[Parallel(n_jobs=4)]: Done 137 tasks      | elapsed: 41.9min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=4)]: Done 173 tasks      | elapsed: 52.8min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 58.8min\n",
      "[Parallel(n_jobs=4)]: Done 213 tasks      | elapsed: 65.3min\n",
      "[Parallel(n_jobs=4)]: Done 234 tasks      | elapsed: 72.2min\n",
      "[Parallel(n_jobs=4)]: Done 257 tasks      | elapsed: 81.3min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 89.7min\n",
      "[Parallel(n_jobs=4)]: Done 305 tasks      | elapsed: 100.3min\n",
      "[Parallel(n_jobs=4)]: Done 330 tasks      | elapsed: 110.0min\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed: 120.4min\n",
      "[Parallel(n_jobs=4)]: Done 384 tasks      | elapsed: 130.2min\n",
      "[Parallel(n_jobs=4)]: Done 413 tasks      | elapsed: 141.5min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 153.4min\n",
      "[Parallel(n_jobs=4)]: Done 473 tasks      | elapsed: 167.1min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed: 181.1min\n",
      "[Parallel(n_jobs=4)]: Done 537 tasks      | elapsed: 194.5min\n",
      "[Parallel(n_jobs=4)]: Done 570 tasks      | elapsed: 207.6min\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(model, param_grid={\n",
    "    \"preprocess_text__encode_text__ngram_range\": [(1,1),(1,2),(2,2),(1,3),(2,3),(3,3),(1,4),(1,5),(1,6)],\n",
    "    \"classify__alpha\": np.exp(np.arange(-2,2,0.1)),\n",
    "    \"classify__fit_prior\": [True, False],\n",
    "}, verbose=10, n_jobs=4)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "pred = clf.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2841,  736,   17,    0],\n",
       "       [ 340, 8882,  379,    0],\n",
       "       [  56, 1487,  593,    0],\n",
       "       [   0,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytest, pred, labels=['abusive', 'normal', 'spam', 'hateful'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (causal_inference_project)",
   "language": "python",
   "name": "pycharm-fb805109"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
